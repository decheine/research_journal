# Bayesian Neural Networks

## ToDos

1. Get Baseline Models + Uncertainty
2. Baseline NNs w. 1D Inputs
3. Uncertainty

---

## Baselines

This just means using some of the typical sklearn models and learning and doing predictions.

---

## Baseline NNs w. 1D Inputs

We can base our work off of a [recent paper](https://arxiv.org/abs/2005.09682) ([Code](https://github.com/kblancato/theia-net)). They were able to use a 1D CNN architecture and got some good results. So let's replicate that!

---

## SOTA Models w. DropOut

* VGG
* PreResNet
* Wide ResNet
* Tiramisu

---

## Stochastic Weight Averaging (SWA)

* [Demo w. PyTorch](https://github.com/izmailovpavel/torch_swa_examples)

---

## Links

* Uncertainty Baselines with `edward2` - [repo](https://github.com/google/uncertainty-baselines)
* Uncertainty Baselines with TensorFlow (OatML) - [repo](https://github.com/OATML/bdl-benchmarks)
* Understanding BDL with PyTorch - [repo](https://github.com/izmailovpavel/understandingbdl)
* Non-Bayesian Benchmarks - [repo](https://www.github.com/hughsalimbeni/bayesian_benchmarks/tree/master/bayesian_benchmarks%2Fmodels)
